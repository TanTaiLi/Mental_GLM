{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3730bd-517b-4c1c-89ff-7841bfd38113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这是第一个完整训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3d1acb-1201-44a0-91e2-00230f6e72dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_train_epochs = 1\n",
    "    output_dir = '/root/autodl-fs/weights/chatglm3-6b_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e147d2cf-4919-4b24-9e43-3b120ab9c537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, AutoModel\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a1bd0d-3bb6-432b-b5f9-c77b982dedc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('/root/tuning_space/Components/')\n",
    "import interact\n",
    "import model_tools\n",
    "from Static import prompt_dict, st, si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a9d856-a53d-41cd-9ca3-0186c3be68d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = '/root/autodl-fs/weights/chatglm3-6b'\n",
    "data_path = '/root/autodl-tmp/dataset/psychology-dataset/data/train.jsonl'\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query_key_value\"],  # lora的目标位置，具体有哪些可选项可打印出源码中的key_list 注意不同的模型中的定义名称不同\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc331aa4-9992-4ab2-8822-8ee8d3a1c6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008275508880615234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26e3b9eaaac494fae4bf742e64677bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.34 s, sys: 28.8 s, total: 36.1 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528572d7-82a1-4c3e-a9f8-2c1663c64db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 6243584000\n",
      "Trainable Parameters: 6243584000\n",
      "Percentage of Trainable Parameters: 100.00%\n",
      "conducting peft lora ---------------\n",
      "Total Parameters: 6247483392\n",
      "Trainable Parameters: 3899392\n",
      "Percentage of Trainable Parameters: 0.06%\n"
     ]
    }
   ],
   "source": [
    "#施加peft lora\n",
    "model_tools.model_profile(model)\n",
    "print('conducting peft lora ---------------')\n",
    "model = get_peft_model(model, config)\n",
    "model_tools.model_profile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64da1570-4e5a-4a58-869a-646da5529a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class instruction_dataset(Dataset):\n",
    "    def __init__(self, data_path:'str', tokenizer, truncate_length, max_query_length):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = []\n",
    "        \n",
    "        with open(data_path, 'r') as file:\n",
    "            for line in file:\n",
    "                sample=json.loads(line)\n",
    "                # input_ids的结构应该为：prompt_tokens, src_tokens, [gMASK], <sop>, tgt_tokens, <eop>, [PAD]... \n",
    "                # 或者简化一点，即为 query, [gMASK], <sop>, answer, <eop>, [PAD]... \n",
    "                # padding的目的是为了对齐各个instance，以组成batch（当然batch_size=1时其实没必要）\n",
    "                # 总体的input_ids的长度不超过truncate_length，其中query的长度不超过max_query_length，同理可以计算出answer的最大长度\n",
    "                max_answer_length = truncate_length - max_query_length - 3\n",
    "                \n",
    "                # 判断query的长度\n",
    "                query = sample['question']\n",
    "                query_ids = tokenizer.encode(query, add_special_tokens=False)\n",
    "                if len(query_ids) > max_query_length:\n",
    "                    query_ids = query_ids[:max_query_length]\n",
    "                \n",
    "                # 判断answer的长度\n",
    "                answer = sample['response_j']\n",
    "                answer_ids = tokenizer.encode(answer, add_special_tokens=False)\n",
    "                if len(answer) > max_answer_length:\n",
    "                    answer_ids = answer_ids[:max_answer_length]\n",
    "                    \n",
    "                # 合并\n",
    "                input_ids = query_ids + [si['[gMASK]']] + [si['sop']] + answer_ids + [si['eop']]\n",
    "                pre_context_length = input_ids.index(si['sop'])\n",
    "                end_answer_index = input_ids.index(si['eop'])\n",
    "                \n",
    "                # padding\n",
    "                padding_length=truncate_length-len(input_ids)\n",
    "                input_ids+=padding_length*[tokenizer.pad_token_id]\n",
    "                \n",
    "                # 制作labels；其中query部分，pad部分均不参与loss的计算 # 因为需要整体向左移动，所以要少填充一个\n",
    "                labels = [-100] * (pre_context_length-0) + input_ids[pre_context_length+1: end_answer_index+1]\n",
    "                labels = labels + [-100] * (truncate_length-len(labels))\n",
    "                \n",
    "                # 制作attention_mask\n",
    "                eop_position = input_ids.index(si['eop'])+1\n",
    "                attention_mask = [True]*eop_position\n",
    "                attention_mask += [False]*(truncate_length-len(attention_mask))\n",
    "                \n",
    "                self.examples.append({\n",
    "                    'query' : query,\n",
    "                    'answer' : answer,\n",
    "                    'input_ids' : input_ids,\n",
    "                    'labels' : labels,\n",
    "                    'attention_mask' : attention_mask,\n",
    "                })\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        instance = self.examples[item]\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285b1119-dddc-4253-8e67-da2137de3950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coll_fn(batch:list):\n",
    "    input_labels = []\n",
    "    labels = []\n",
    "    attention_mask = []\n",
    "    for sample in batch:\n",
    "        # 实际上词表长度只有65024，所以int32就可以了 # attention_mask用bool就行 (我收回我的画，完全是玄学)\n",
    "        input_labels.append(torch.tensor(sample['input_ids'], dtype=torch.long))\n",
    "        labels.append(torch.tensor(sample['labels'], dtype=torch.long))\n",
    "        attention_mask.append(torch.tensor(sample['attention_mask'], dtype=torch.float64)) #, dtype=torch.bool\n",
    "    batch = {'input_ids':input_labels, 'labels':labels, 'attention_mask': attention_mask}\n",
    "    batch = {name:torch.stack(item).cuda() for name,item in batch.items()} #对于一个元素不为基本元素的list，需要使用stack方法\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41977962-673c-48e9-a612-ea7ccca3a52f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 66.1 ms, total: 4.77 s\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "finetuning_instruction=instruction_dataset(data_path, tokenizer, 128, 32)\n",
    "instruction_loader = DataLoader(finetuning_instruction, batch_size=2, shuffle=True, collate_fn=coll_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3459d23c-c1cf-4408-a5ac-e7ca67854edb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  307, 30953, 30924, 10346,   356,  7841,   290, 19834, 30928,   291,\n",
      "           552,  2482, 30930, 64790, 64792,  2871, 14474, 30928,   457,   330,\n",
      "           260,  2529, 10057,   289,  5559, 30932,   498,   354, 30953, 30917,\n",
      "          1447,   289,  5550,   267,  6840,  6157,   291,   260,  3544,   293,\n",
      "          1625, 30941, 11000,  4686,   285,  2313, 30930,  2641, 30953, 30917,\n",
      "           636,  1811,   289,  5478,   612, 10419,  2326,   293,  1053,   260,\n",
      "          1377,   289,   833,   344,  5559,   475, 19834, 30928, 30930,   666,\n",
      "           740,  1860,  5000,  4917,  3462, 30932,  2310,  3500,   356,   475,\n",
      "          4881, 30932,   400, 10944,  2666,   289,  1378,   475,  1254, 30941,\n",
      "         29038, 30930, 64793,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  307, 30953, 30924,  1709,  6555, 29308,   356,   267,  2812,   290,\n",
      "           260,  4374,   544, 30930,   577,  6032,   659,   267,  1898,   471,\n",
      "          1336,   490,  1626, 30930, 64790, 64792,   353,  2812,   290,   260,\n",
      "          4374,   544,   457,   330,   260,  2529,   293, 12643,  1524, 30932,\n",
      "           293,   354, 30953, 30917,  1447,   289,  1025,   267,   622,   289,\n",
      "         17214,   318,   293,  1226,   475, 10146, 30930,  2641, 30953, 30917,\n",
      "          1785,   565,   475,  7841,   293,  5550,  2666,   289,  6472,   475,\n",
      "          4374,   544, 30953, 30917,  4554, 30930,   657,   457,   629,   636,\n",
      "           331,  5000, 29308,  6800,   289,   833,   344,  5559,   475, 17100,\n",
      "         30930, 64793,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  2871, 14474, 30928,   457,   330,   260,\n",
      "          2529, 10057,   289,  5559, 30932,   498,   354, 30953, 30917,  1447,\n",
      "           289,  5550,   267,  6840,  6157,   291,   260,  3544,   293,  1625,\n",
      "         30941, 11000,  4686,   285,  2313, 30930,  2641, 30953, 30917,   636,\n",
      "          1811,   289,  5478,   612, 10419,  2326,   293,  1053,   260,  1377,\n",
      "           289,   833,   344,  5559,   475, 19834, 30928, 30930,   666,   740,\n",
      "          1860,  5000,  4917,  3462, 30932,  2310,  3500,   356,   475,  4881,\n",
      "         30932,   400, 10944,  2666,   289,  1378,   475,  1254, 30941, 29038,\n",
      "         30930, 64793,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,   353,  2812,   290,   260,  4374,\n",
      "           544,   457,   330,   260,  2529,   293, 12643,  1524, 30932,   293,\n",
      "           354, 30953, 30917,  1447,   289,  1025,   267,   622,   289, 17214,\n",
      "           318,   293,  1226,   475, 10146, 30930,  2641, 30953, 30917,  1785,\n",
      "           565,   475,  7841,   293,  5550,  2666,   289,  6472,   475,  4374,\n",
      "           544, 30953, 30917,  4554, 30930,   657,   457,   629,   636,   331,\n",
      "          5000, 29308,  6800,   289,   833,   344,  5559,   475, 17100, 30930,\n",
      "         64793,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], device='cuda:0', dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "for item in instruction_loader:\n",
    "    pass\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf0607dd-e9ae-4233-8d09-679bf466f26e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义参数优化器 & 学习率优化器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=50,\n",
    "        num_training_steps=(len(instruction_loader) * CFG.num_train_epochs),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff0d58-18e6-450e-b0d7-e3c667c1b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.2441, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:05,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.5638, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:08,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.5320, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:12,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:15,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.8132, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:19,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.7698, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [00:22,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.8154, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:26,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.6342, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:29,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:33,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.6912, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:36,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.9155, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111it [00:40,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.0864, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [00:43,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.2593, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:47,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.5788, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [00:50,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [00:54,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.6222, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161it [00:58,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8207, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [01:01,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.3772, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [01:05,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.6305, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "191it [01:08,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.4686, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:12,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.5191, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [01:15,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.7992, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [01:19,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.7659, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [01:23,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4591, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [01:26,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4170, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251it [01:30,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8910, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [01:33,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8380, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "271it [01:37,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8038, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281it [01:40,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3111, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "291it [01:44,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1503, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:47,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5290, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "311it [01:51,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9817, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321it [01:55,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7942, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331it [01:58,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1678, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "341it [02:02,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9975, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "351it [02:05,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8508, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [02:09,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3617, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "363it [02:10,  2.79it/s]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(CFG.num_train_epochs):\n",
    "    for step, batch in tqdm(enumerate(instruction_loader)):\n",
    "        # 前向传播\n",
    "        outputs = model(**batch)\n",
    "        #break\n",
    "        # 计算loss\n",
    "        loss = outputs.loss\n",
    "        if step%10==0:print(loss)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 优化器调度\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d849b98-412b-4b42-957e-d357eb9da4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型的保存\n",
    "model.save_pretrained(CFG.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafa9dc-7dbd-48a7-b811-8ff9fa75b411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(CFG.num_train_epochs):\n",
    "    for step, batch in tqdm(enumerate(instruction_loader)):\n",
    "        # 前向传播\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        max_indices = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        #print(max_indices)\n",
    "        #print(outputs.logits)\n",
    "        #print(batch['labels'])\n",
    "        #break\n",
    "        # 计算loss\n",
    "        loss = outputs.loss\n",
    "        print(loss)\n",
    "        if step==10:break\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        for name,param in model.named_parameters():\n",
    "            break\n",
    "            print(name, param.grad)\n",
    "        print('***'*30)\n",
    "        if step==2:break\n",
    "        # 优化器调度\n",
    "        optimizer.step()\n",
    "        for name,param in model.named_parameters():\n",
    "            break\n",
    "            print(name, param.grad)\n",
    "        #lr_scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
