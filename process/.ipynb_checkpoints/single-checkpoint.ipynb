{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f7c489-1021-4adf-9953-d2852bfe6381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import os\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "sys.path.append('/root/tuning_space/Components/')\n",
    "from Static import prompt_dict, si\n",
    "\n",
    "raw_data_path='/root/autodl-tmp/weights/smile/data'\n",
    "aim_path='/root/autodl-tmp/dataset/OESD-GG-zh_cn-1/single_query.jsonl'\n",
    "model_path = '/root/autodl-tmp/weights/chatglm3-6b'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e2c865-3d8a-4bfe-96c5-c3b0474c9ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class instruction_dataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, truncate_length, max_query_length, query_key, answer_key, max_sample=None, num_workers=12):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.truncate_length = truncate_length\n",
    "        self.max_query_length = max_query_length\n",
    "        self.query_key = query_key\n",
    "        self.answer_key = answer_key\n",
    "        self.examples = []\n",
    "\n",
    "        # 使用多进程读取和处理数据\n",
    "        with open(data_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            if max_sample:\n",
    "                lines = lines[:max_sample]\n",
    "\n",
    "        with Pool(num_workers) as p:\n",
    "            self.examples = p.map(self.process_line, lines)\n",
    "\n",
    "    def process_line(self, line):\n",
    "        sample=json.loads(line)\n",
    "        max_answer_length = self.truncate_length - self.max_query_length - 3\n",
    "\n",
    "        # 判断query的长度\n",
    "        query = sample[self.query_key]\n",
    "        query_ids = self.tokenizer.encode(query, add_special_tokens=False)\n",
    "        if len(query_ids) > self.max_query_length:\n",
    "            query_ids = query_ids[:self.max_query_length]\n",
    "\n",
    "        # 判断answer的长度\n",
    "        answer = sample[self.answer_key]\n",
    "        answer_ids = self.tokenizer.encode(answer, add_special_tokens=False)\n",
    "        if len(answer) > max_answer_length:\n",
    "            answer_ids = answer_ids[:max_answer_length]\n",
    "\n",
    "        # 合并\n",
    "        input_ids = query_ids + [si['[gMASK]']] + [si['sop']] + answer_ids + [si['eop']]\n",
    "        pre_context_length = input_ids.index(si['sop'])\n",
    "        end_answer_index = input_ids.index(si['eop'])\n",
    "\n",
    "        # padding\n",
    "        padding_length=self.truncate_length-len(input_ids)\n",
    "        input_ids+=padding_length*[self.tokenizer.pad_token_id]\n",
    "\n",
    "        # 制作labels；其中query部分，pad部分均不参与loss的计算 # 因为需要整体向左移动，所以要少填充一个\n",
    "        labels = [-100] * (pre_context_length+1) + input_ids[pre_context_length+1: end_answer_index+1]\n",
    "        labels = labels + [-100] * (self.truncate_length-len(labels))\n",
    "\n",
    "        # 制作attention_mask\n",
    "        eop_position = input_ids.index(si['eop'])+1\n",
    "        attention_mask = [True]*eop_position\n",
    "        attention_mask += [False]*(self.truncate_length-len(attention_mask))\n",
    "\n",
    "        return {\n",
    "            'query': query,\n",
    "            'answer': answer,\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.examples[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4439ca55-a25b-4977-9919-1a3cfbe0e62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Assistant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/root/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/root/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_409041/909619900.py\", line 31, in process_line\n    answer = sample[self.answer_key]\nKeyError: 'Assistant'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m temp\u001b[38;5;241m=\u001b[39m\u001b[43minstruction_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maim_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_query_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAssistant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36minstruction_dataset.__init__\u001b[0;34m(self, data_path, tokenizer, truncate_length, max_query_length, query_key, answer_key, max_sample, num_workers)\u001b[0m\n\u001b[1;32m     15\u001b[0m         lines \u001b[38;5;241m=\u001b[39m lines[:max_sample]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_workers) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Assistant'"
     ]
    }
   ],
   "source": [
    "temp=instruction_dataset(data_path=aim_path, tokenizer=tokenizer, truncate_length=192, max_query_length=64, query_key='User', answer_key='Assisstant', max_sample=5, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e642f15-9d77-47da-bf15-40f3a15d0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=None\n",
    "for item in temp:\n",
    "    sample=item\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2561c2-f26a-480b-987a-74c453f3caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sample.values():\n",
    "    print(len(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0fb72-dc26-43f7-9751-a10438d36198",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=sample['input_ids']\n",
    "labels=sample['labels']\n",
    "attention_mask=sample['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbd416-fbc5-4e28-8291-d4563468959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93040c44-c126-4961-b4eb-25eb0119b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
